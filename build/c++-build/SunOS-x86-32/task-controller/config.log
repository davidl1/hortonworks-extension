This file contains any messages produced by compilers while
running configure, to aid debugging if configure makes a mistake.

It was created by linux-task-controller configure 1.0.0, which was
generated by GNU Autoconf 2.63.  Invocation command line was

  $ /root/mydev/hadoop-1.0.3.16/src/c++/task-controller/configure --prefix=/root/mydev/hadoop-1.0.3.16/build/hadoop-1.0.4-SNAPSHOT

## --------- ##
## Platform. ##
## --------- ##

hostname = dn-177
uname -m = i86pc
uname -r = 5.11
uname -s = SunOS
uname -v = ffabcc210746

/usr/bin/uname -p = i386
/bin/uname -X     = System = SunOS
Node = dn-177
Release = 5.11
KernelID = ffabcc210746
Machine = i86pc
BusType = <unknown>
Serial = <unknown>
Users = <unknown>
OEM# = 0
Origin# = 1
NumCPU = 1

/bin/arch              = i86pc
/usr/bin/arch -k       = i86pc
/usr/convex/getsysinfo = unknown
/usr/bin/hostinfo      = unknown
/bin/machine           = unknown
/usr/bin/oslevel       = unknown
/bin/universe          = unknown

PATH: /usr/java/bin
PATH: /root/mybin/apache-maven-3.0.4/bin
PATH: /usr/gnu/bin
PATH: /usr/bin
PATH: /sbin
PATH: /usr/sbin
PATH: /usr/local/bin
PATH: /usr/local/sbin


## ----------- ##
## Core tests. ##
## ----------- ##

configure:2086: checking for gcc
configure:2102: found /usr/bin/gcc
configure:2113: result: gcc
configure:2345: checking for C compiler version
configure:2353: gcc --version >&5
gcc (GCC) 3.4.3 (csl-sol210-3_4-20050802)
Copyright (C) 2004 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

configure:2357: $? = 0
configure:2364: gcc -v >&5
Reading specs from /usr/sfw/lib/gcc/i386-pc-solaris2.11/3.4.3/specs
Configured with: /myshare/builds/dilos-userland/dilos-userland-review/components/gcc3/gcc-3.4.3/configure --prefix=/usr/sfw --mandir=/usr/sfw/share/man --infodir=/usr/sfw/share/info --without-gnu-ld --with-ld=/usr/bin/ld --enable-languages=c,c++,f77,objc --enable-shared --with-gnu-as --with-as=/usr/gnu/bin/as
Thread model: posix
gcc version 3.4.3 (csl-sol210-3_4-20050802)
configure:2368: $? = 0
configure:2375: gcc -V >&5
gcc: `-V' option must have argument
configure:2379: $? = 1
configure:2402: checking for C compiler default output file name
configure:2424: gcc -DHADOOP_CONF_DIR=/etc/hadoop   conftest.c  >&5
configure:2428: $? = 0
configure:2466: result: a.out
configure:2485: checking whether the C compiler works
configure:2495: ./a.out
configure:2499: $? = 0
configure:2518: result: yes
configure:2525: checking whether we are cross compiling
configure:2527: result: no
configure:2530: checking for suffix of executables
configure:2537: gcc -o conftest -DHADOOP_CONF_DIR=/etc/hadoop   conftest.c  >&5
configure:2541: $? = 0
configure:2567: result: 
configure:2573: checking for suffix of object files
configure:2599: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:2603: $? = 0
configure:2628: result: o
configure:2632: checking whether we are using the GNU C compiler
configure:2661: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:2668: $? = 0
configure:2685: result: yes
configure:2694: checking whether gcc accepts -g
configure:2724: gcc -c -g  conftest.c >&5
configure:2731: $? = 0
configure:2832: result: yes
configure:2849: checking for gcc option to accept ISO C89
configure:2923: gcc  -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:2930: $? = 0
configure:2953: result: none needed
configure:2977: checking how to run the C preprocessor
configure:3017: gcc -E  conftest.c
configure:3024: $? = 0
configure:3055: gcc -E  conftest.c
conftest.c:8:28: ac_nonexistent.h: No such file or directory
configure:3062: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "linux-task-controller"
| #define PACKAGE_TARNAME "linux-task-controller"
| #define PACKAGE_VERSION "1.0.0"
| #define PACKAGE_STRING "linux-task-controller 1.0.0"
| #define PACKAGE_BUGREPORT "mapreduce-dev@hadoop.apache.org"
| /* end confdefs.h.  */
| #include <ac_nonexistent.h>
configure:3095: result: gcc -E
configure:3124: gcc -E  conftest.c
configure:3131: $? = 0
configure:3162: gcc -E  conftest.c
conftest.c:8:28: ac_nonexistent.h: No such file or directory
configure:3169: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "linux-task-controller"
| #define PACKAGE_TARNAME "linux-task-controller"
| #define PACKAGE_VERSION "1.0.0"
| #define PACKAGE_STRING "linux-task-controller 1.0.0"
| #define PACKAGE_BUGREPORT "mapreduce-dev@hadoop.apache.org"
| /* end confdefs.h.  */
| #include <ac_nonexistent.h>
configure:3209: checking for grep that handles long lines and -e
configure:3269: result: /usr/gnu/bin/grep
configure:3274: checking for egrep
configure:3338: result: /usr/gnu/bin/grep -E
configure:3343: checking for ANSI C header files
configure:3373: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:3380: $? = 0
configure:3479: gcc -o conftest -DHADOOP_CONF_DIR=/etc/hadoop   conftest.c  >&5
configure:3483: $? = 0
configure:3489: ./conftest
configure:3493: $? = 0
configure:3511: result: yes
configure:3535: checking for sys/types.h
configure:3556: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:3563: $? = 0
configure:3580: result: yes
configure:3535: checking for sys/stat.h
configure:3556: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:3563: $? = 0
configure:3580: result: yes
configure:3535: checking for stdlib.h
configure:3556: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:3563: $? = 0
configure:3580: result: yes
configure:3535: checking for string.h
configure:3556: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:3563: $? = 0
configure:3580: result: yes
configure:3535: checking for memory.h
configure:3556: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:3563: $? = 0
configure:3580: result: yes
configure:3535: checking for strings.h
configure:3556: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:3563: $? = 0
configure:3580: result: yes
configure:3535: checking for inttypes.h
configure:3556: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:3563: $? = 0
configure:3580: result: yes
configure:3535: checking for stdint.h
configure:3556: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:3563: $? = 0
configure:3580: result: yes
configure:3535: checking for unistd.h
configure:3556: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:3563: $? = 0
configure:3580: result: yes
configure:3605: checking minix/config.h usability
configure:3622: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
conftest.c:51:26: minix/config.h: No such file or directory
configure:3629: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "linux-task-controller"
| #define PACKAGE_TARNAME "linux-task-controller"
| #define PACKAGE_VERSION "1.0.0"
| #define PACKAGE_STRING "linux-task-controller 1.0.0"
| #define PACKAGE_BUGREPORT "mapreduce-dev@hadoop.apache.org"
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| /* end confdefs.h.  */
| #include <stdio.h>
| #ifdef HAVE_SYS_TYPES_H
| # include <sys/types.h>
| #endif
| #ifdef HAVE_SYS_STAT_H
| # include <sys/stat.h>
| #endif
| #ifdef STDC_HEADERS
| # include <stdlib.h>
| # include <stddef.h>
| #else
| # ifdef HAVE_STDLIB_H
| #  include <stdlib.h>
| # endif
| #endif
| #ifdef HAVE_STRING_H
| # if !defined STDC_HEADERS && defined HAVE_MEMORY_H
| #  include <memory.h>
| # endif
| # include <string.h>
| #endif
| #ifdef HAVE_STRINGS_H
| # include <strings.h>
| #endif
| #ifdef HAVE_INTTYPES_H
| # include <inttypes.h>
| #endif
| #ifdef HAVE_STDINT_H
| # include <stdint.h>
| #endif
| #ifdef HAVE_UNISTD_H
| # include <unistd.h>
| #endif
| #include <minix/config.h>
configure:3643: result: no
configure:3647: checking minix/config.h presence
configure:3662: gcc -E  conftest.c
conftest.c:18:26: minix/config.h: No such file or directory
configure:3669: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "linux-task-controller"
| #define PACKAGE_TARNAME "linux-task-controller"
| #define PACKAGE_VERSION "1.0.0"
| #define PACKAGE_STRING "linux-task-controller 1.0.0"
| #define PACKAGE_BUGREPORT "mapreduce-dev@hadoop.apache.org"
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| /* end confdefs.h.  */
| #include <minix/config.h>
configure:3683: result: no
configure:3716: checking for minix/config.h
configure:3723: result: no
configure:3754: checking whether it is safe to define __EXTENSIONS__
configure:3782: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:3789: $? = 0
configure:3804: result: yes
configure:3835: checking for special C compiler options needed for large files
configure:3930: result: no
configure:3936: checking for _FILE_OFFSET_BITS value needed for large files
configure:3971: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
conftest.c:29: warning: left shift count >= width of type
conftest.c:29: warning: left shift count >= width of type
conftest.c:31: error: size of array `off_t_is_large' is negative
configure:3978: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "linux-task-controller"
| #define PACKAGE_TARNAME "linux-task-controller"
| #define PACKAGE_VERSION "1.0.0"
| #define PACKAGE_STRING "linux-task-controller 1.0.0"
| #define PACKAGE_BUGREPORT "mapreduce-dev@hadoop.apache.org"
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define __EXTENSIONS__ 1
| #define _ALL_SOURCE 1
| #define _GNU_SOURCE 1
| #define _POSIX_PTHREAD_SEMANTICS 1
| #define _TANDEM_SOURCE 1
| /* end confdefs.h.  */
| #include <sys/types.h>
|  /* Check that off_t can represent 2**63 - 1 correctly.
|     We can't simply define LARGE_OFF_T to be 9223372036854775807,
|     since some C++ compilers masquerading as C compilers
|     incorrectly reject 9223372036854775807.  */
| #define LARGE_OFF_T (((off_t) 1 << 62) - 1 + ((off_t) 1 << 62))
|   int off_t_is_large[(LARGE_OFF_T % 2147483629 == 721
| 		       && LARGE_OFF_T % 2147483647 == 1)
| 		      ? 1 : -1];
| int
| main ()
| {
| 
|   ;
|   return 0;
| }
configure:4022: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:4029: $? = 0
configure:4047: result: 64
configure:4234: checking for a BSD-compatible install
configure:4302: result: /usr/gnu/bin/install -c
configure:4313: checking whether build environment is sane
configure:4356: result: yes
configure:4381: checking for a thread-safe mkdir -p
configure:4420: result: /usr/gnu/bin/mkdir -p
configure:4433: checking for gawk
configure:4449: found /usr/bin/gawk
configure:4460: result: gawk
configure:4471: checking whether make sets $(MAKE)
configure:4493: result: yes
configure:4523: checking for style of include used by make
configure:4551: result: GNU
configure:4740: checking dependency style of gcc
configure:4831: result: gcc3
configure:5182: checking for gcc
configure:5209: result: gcc
configure:5441: checking for C compiler version
configure:5449: gcc --version >&5
gcc (GCC) 3.4.3 (csl-sol210-3_4-20050802)
Copyright (C) 2004 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

configure:5453: $? = 0
configure:5460: gcc -v >&5
Reading specs from /usr/sfw/lib/gcc/i386-pc-solaris2.11/3.4.3/specs
Configured with: /myshare/builds/dilos-userland/dilos-userland-review/components/gcc3/gcc-3.4.3/configure --prefix=/usr/sfw --mandir=/usr/sfw/share/man --infodir=/usr/sfw/share/info --without-gnu-ld --with-ld=/usr/bin/ld --enable-languages=c,c++,f77,objc --enable-shared --with-gnu-as --with-as=/usr/gnu/bin/as
Thread model: posix
gcc version 3.4.3 (csl-sol210-3_4-20050802)
configure:5464: $? = 0
configure:5471: gcc -V >&5
gcc: `-V' option must have argument
configure:5475: $? = 1
configure:5478: checking whether we are using the GNU C compiler
configure:5531: result: yes
configure:5540: checking whether gcc accepts -g
configure:5678: result: yes
configure:5695: checking for gcc option to accept ISO C89
configure:5799: result: none needed
configure:5818: checking whether gcc and cc understand -c and -o together
configure:5853: gcc -c conftest.c -o conftest2.o >&5
configure:5857: $? = 0
configure:5863: gcc -c conftest.c -o conftest2.o >&5
configure:5867: $? = 0
configure:5878: cc -c conftest.c >&5
configure:5882: $? = 0
configure:5890: cc -c conftest.c -o conftest2.o >&5
configure:5894: $? = 0
configure:5900: cc -c conftest.c -o conftest2.o >&5
configure:5904: $? = 0
configure:5922: result: yes
configure:6026: checking build system type
configure:6044: result: i386-pc-solaris2.11
configure:6066: checking host system type
configure:6081: result: i386-pc-solaris2.11
configure:6103: checking for a sed that does not truncate output
configure:6157: result: /usr/gnu/bin/sed
configure:6171: checking for ld used by gcc
configure:6238: result: /usr/bin/ld
configure:6247: checking if the linker (/usr/bin/ld) is GNU ld
configure:6262: result: no
configure:6267: checking for /usr/bin/ld option to reload object files
configure:6274: result: -r
configure:6292: checking for BSD-compatible nm
configure:6341: result: /usr/gnu/bin/nm -B
configure:6345: checking whether ln -s works
configure:6349: result: yes
configure:6356: checking how to recognise dependent libraries
configure:6532: result: pass_all
configure:6780: checking dlfcn.h usability
configure:6797: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:6804: $? = 0
configure:6818: result: yes
configure:6822: checking dlfcn.h presence
configure:6837: gcc -E  conftest.c
configure:6844: $? = 0
configure:6858: result: yes
configure:6891: checking for dlfcn.h
configure:6900: result: yes
configure:6973: checking for g++
configure:6989: found /usr/bin/g++
configure:7000: result: g++
configure:7027: checking for C++ compiler version
configure:7035: g++ --version >&5
g++ (GCC) 3.4.3 (csl-sol210-3_4-20050802)
Copyright (C) 2004 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

configure:7039: $? = 0
configure:7046: g++ -v >&5
Reading specs from /usr/sfw/lib/gcc/i386-pc-solaris2.11/3.4.3/specs
Configured with: /myshare/builds/dilos-userland/dilos-userland-review/components/gcc3/gcc-3.4.3/configure --prefix=/usr/sfw --mandir=/usr/sfw/share/man --infodir=/usr/sfw/share/info --without-gnu-ld --with-ld=/usr/bin/ld --enable-languages=c,c++,f77,objc --enable-shared --with-gnu-as --with-as=/usr/gnu/bin/as
Thread model: posix
gcc version 3.4.3 (csl-sol210-3_4-20050802)
configure:7050: $? = 0
configure:7057: g++ -V >&5
g++: `-V' option must have argument
configure:7061: $? = 1
configure:7064: checking whether we are using the GNU C++ compiler
configure:7093: g++ -c   conftest.cpp >&5
configure:7100: $? = 0
configure:7117: result: yes
configure:7126: checking whether g++ accepts -g
configure:7156: g++ -c -g  conftest.cpp >&5
configure:7163: $? = 0
configure:7264: result: yes
configure:7289: checking dependency style of g++
configure:7380: result: gcc3
configure:7397: checking dependency style of g++
configure:7488: result: gcc3
configure:7513: checking how to run the C++ preprocessor
configure:7549: g++ -E  conftest.cpp
configure:7556: $? = 0
configure:7587: g++ -E  conftest.cpp
conftest.cpp:27:28: ac_nonexistent.h: No such file or directory
configure:7594: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "linux-task-controller"
| #define PACKAGE_TARNAME "linux-task-controller"
| #define PACKAGE_VERSION "1.0.0"
| #define PACKAGE_STRING "linux-task-controller 1.0.0"
| #define PACKAGE_BUGREPORT "mapreduce-dev@hadoop.apache.org"
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define __EXTENSIONS__ 1
| #define _ALL_SOURCE 1
| #define _GNU_SOURCE 1
| #define _POSIX_PTHREAD_SEMANTICS 1
| #define _TANDEM_SOURCE 1
| #define _FILE_OFFSET_BITS 64
| #define PACKAGE "linux-task-controller"
| #define VERSION "1.0.0"
| #define HAVE_DLFCN_H 1
| /* end confdefs.h.  */
| #include <ac_nonexistent.h>
configure:7627: result: g++ -E
configure:7656: g++ -E  conftest.cpp
configure:7663: $? = 0
configure:7694: g++ -E  conftest.cpp
conftest.cpp:27:28: ac_nonexistent.h: No such file or directory
configure:7701: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "linux-task-controller"
| #define PACKAGE_TARNAME "linux-task-controller"
| #define PACKAGE_VERSION "1.0.0"
| #define PACKAGE_STRING "linux-task-controller 1.0.0"
| #define PACKAGE_BUGREPORT "mapreduce-dev@hadoop.apache.org"
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define __EXTENSIONS__ 1
| #define _ALL_SOURCE 1
| #define _GNU_SOURCE 1
| #define _POSIX_PTHREAD_SEMANTICS 1
| #define _TANDEM_SOURCE 1
| #define _FILE_OFFSET_BITS 64
| #define PACKAGE "linux-task-controller"
| #define VERSION "1.0.0"
| #define HAVE_DLFCN_H 1
| /* end confdefs.h.  */
| #include <ac_nonexistent.h>
configure:7796: checking for g77
configure:7812: found /usr/bin/g77
configure:7823: result: g77
configure:7849: checking for Fortran 77 compiler version
configure:7857: g77 --version >&5
GNU Fortran (GCC) 3.4.3 (csl-sol210-3_4-20050802)
Copyright (C) 2004 Free Software Foundation, Inc.

GNU Fortran comes with NO WARRANTY, to the extent permitted by law.
You may redistribute copies of GNU Fortran
under the terms of the GNU General Public License.
For more information about these matters, see the file named COPYING
or type the command `info -f g77 Copying'.
configure:7861: $? = 0
configure:7868: g77 -v >&5
Reading specs from /usr/sfw/lib/gcc/i386-pc-solaris2.11/3.4.3/specs
Configured with: /myshare/builds/dilos-userland/dilos-userland-review/components/gcc3/gcc-3.4.3/configure --prefix=/usr/sfw --mandir=/usr/sfw/share/man --infodir=/usr/sfw/share/info --without-gnu-ld --with-ld=/usr/bin/ld --enable-languages=c,c++,f77,objc --enable-shared --with-gnu-as --with-as=/usr/gnu/bin/as
Thread model: posix
gcc version 3.4.3 (csl-sol210-3_4-20050802)
configure:7872: $? = 0
configure:7879: g77 -V >&5
g77: `-V' option must have argument
configure:7883: $? = 1
configure:7891: checking whether we are using the GNU Fortran 77 compiler
configure:7910: g77 -c  conftest.F >&5
configure:7917: $? = 0
configure:7934: result: yes
configure:7940: checking whether g77 accepts -g
configure:7957: g77 -c -g conftest.f >&5
configure:7964: $? = 0
configure:7980: result: yes
configure:8014: checking the maximum length of command line arguments
configure:8123: result: 262144
configure:8134: checking command to parse /usr/gnu/bin/nm -B output from gcc object
configure:8239: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:8242: $? = 0
configure:8246: /usr/gnu/bin/nm -B conftest.o \| sed -n -e 's/^.*[ 	]\([ABCDGIRSTW][ABCDGIRSTW]*\)[ 	][ 	]*\([_A-Za-z][_A-Za-z0-9]*\)$/\1 \2 \2/p' \> conftest.nm
configure:8249: $? = 0
configure:8301: gcc -o conftest -DHADOOP_CONF_DIR=/etc/hadoop   conftest.c conftstm.o >&5
configure:8304: $? = 0
configure:8342: result: ok
configure:8346: checking for objdir
configure:8361: result: .libs
configure:8453: checking for ar
configure:8469: found /usr/gnu/bin/ar
configure:8480: result: ar
configure:8545: checking for ranlib
configure:8561: found /usr/gnu/bin/ranlib
configure:8572: result: ranlib
configure:8637: checking for strip
configure:8653: found /usr/gnu/bin/strip
configure:8664: result: strip
configure:8946: checking if gcc supports -fno-rtti -fno-exceptions
configure:8964: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  -fno-rtti -fno-exceptions conftest.c >&5
cc1: warning: command line option "-fno-rtti" is valid for C++/ObjC++ but not for C
configure:8968: $? = 0
configure:8981: result: no
configure:8996: checking for gcc option to produce PIC
configure:9206: result: -fPIC
configure:9214: checking if gcc PIC flag -fPIC works
configure:9232: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  -fPIC -DPIC conftest.c >&5
configure:9236: $? = 0
configure:9249: result: yes
configure:9277: checking if gcc static flag -static works
configure:9305: result: no
configure:9315: checking if gcc supports -c -o file.o
configure:9336: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  -o out/conftest2.o conftest.c >&5
configure:9340: $? = 0
configure:9362: result: yes
configure:9388: checking whether the gcc linker (/usr/bin/ld) supports shared libraries
configure:10350: result: yes
configure:10371: checking whether -lc should be explicitly linked in
configure:10376: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:10379: $? = 0
configure:10394: gcc -shared -Wl,-h -Wl,conftest -o conftest conftest.o  -v 2\>\&1 \| grep  -lc  \>/dev/null 2\>\&1
configure:10397: $? = 1
configure:10409: result: yes
configure:10417: checking dynamic linker characteristics
configure:11005: result: solaris2.11 ld.so
configure:11014: checking how to hardcode library paths into programs
configure:11039: result: immediate
configure:11053: checking whether stripping libraries is possible
configure:11058: result: yes
configure:11887: checking if libtool supports shared libraries
configure:11889: result: yes
configure:11892: checking whether to build shared libraries
configure:11913: result: yes
configure:11916: checking whether to build static libraries
configure:11920: result: yes
configure:12012: creating libtool
configure:12600: checking for ld used by g++
configure:12667: result: /usr/bin/ld
configure:12676: checking if the linker (/usr/bin/ld) is GNU ld
configure:12691: result: no
configure:12742: checking whether the g++ linker (/usr/bin/ld) supports shared libraries
configure:13684: result: yes
configure:13702: g++ -c -g -O2  conftest.cpp >&5
configure:13705: $? = 0
configure:13824: checking for g++ option to produce PIC
configure:14098: result: -fPIC
configure:14106: checking if g++ PIC flag -fPIC works
configure:14124: g++ -c -g -O2  -fPIC -DPIC conftest.cpp >&5
configure:14128: $? = 0
configure:14141: result: yes
configure:14169: checking if g++ static flag -static works
configure:14197: result: no
configure:14207: checking if g++ supports -c -o file.o
configure:14228: g++ -c -g -O2  -o out/conftest2.o conftest.cpp >&5
configure:14232: $? = 0
configure:14254: result: yes
configure:14280: checking whether the g++ linker (/usr/bin/ld) supports shared libraries
configure:14305: result: yes
configure:14372: checking dynamic linker characteristics
configure:14960: result: solaris2.11 ld.so
configure:14969: checking how to hardcode library paths into programs
configure:14994: result: immediate
configure:15520: checking if libtool supports shared libraries
configure:15522: result: yes
configure:15525: checking whether to build shared libraries
configure:15545: result: yes
configure:15548: checking whether to build static libraries
configure:15552: result: yes
configure:15562: checking for g77 option to produce PIC
configure:15772: result: -fPIC
configure:15780: checking if g77 PIC flag -fPIC works
configure:15798: g77 -c -g -O2 -fPIC conftest.f >&5
configure:15802: $? = 0
configure:15815: result: yes
configure:15843: checking if g77 static flag -static works
configure:15871: result: no
configure:15881: checking if g77 supports -c -o file.o
configure:15902: g77 -c -g -O2 -o out/conftest2.o conftest.f >&5
configure:15906: $? = 0
configure:15928: result: yes
configure:15954: checking whether the g77 linker (/usr/bin/ld) supports shared libraries
configure:16896: result: yes
configure:16963: checking dynamic linker characteristics
configure:17551: result: solaris2.11 ld.so
configure:17560: checking how to hardcode library paths into programs
configure:17585: result: immediate
configure:21165: checking for unistd.h
configure:21172: result: yes
configure:21313: checking for stdbool.h that conforms to C99
configure:21408: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:21415: $? = 0
configure:21430: result: yes
configure:21432: checking for _Bool
configure:21460: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:21467: $? = 0
configure:21494: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
conftest.c: In function `main':
conftest.c:64: error: syntax error before ')' token
configure:21501: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "linux-task-controller"
| #define PACKAGE_TARNAME "linux-task-controller"
| #define PACKAGE_VERSION "1.0.0"
| #define PACKAGE_STRING "linux-task-controller 1.0.0"
| #define PACKAGE_BUGREPORT "mapreduce-dev@hadoop.apache.org"
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define __EXTENSIONS__ 1
| #define _ALL_SOURCE 1
| #define _GNU_SOURCE 1
| #define _POSIX_PTHREAD_SEMANTICS 1
| #define _TANDEM_SOURCE 1
| #define _FILE_OFFSET_BITS 64
| #define PACKAGE "linux-task-controller"
| #define VERSION "1.0.0"
| #define HAVE_DLFCN_H 1
| #define HAVE_UNISTD_H 1
| /* end confdefs.h.  */
| #include <stdio.h>
| #ifdef HAVE_SYS_TYPES_H
| # include <sys/types.h>
| #endif
| #ifdef HAVE_SYS_STAT_H
| # include <sys/stat.h>
| #endif
| #ifdef STDC_HEADERS
| # include <stdlib.h>
| # include <stddef.h>
| #else
| # ifdef HAVE_STDLIB_H
| #  include <stdlib.h>
| # endif
| #endif
| #ifdef HAVE_STRING_H
| # if !defined STDC_HEADERS && defined HAVE_MEMORY_H
| #  include <memory.h>
| # endif
| # include <string.h>
| #endif
| #ifdef HAVE_STRINGS_H
| # include <strings.h>
| #endif
| #ifdef HAVE_INTTYPES_H
| # include <inttypes.h>
| #endif
| #ifdef HAVE_STDINT_H
| # include <stdint.h>
| #endif
| #ifdef HAVE_UNISTD_H
| # include <unistd.h>
| #endif
| int
| main ()
| {
| if (sizeof ((_Bool)))
| 	  return 0;
|   ;
|   return 0;
| }
configure:21524: result: yes
configure:21543: checking for an ANSI C-conforming const
configure:21618: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:21625: $? = 0
configure:21640: result: yes
configure:21650: checking for off_t
configure:21678: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:21685: $? = 0
configure:21712: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
conftest.c: In function `main':
conftest.c:66: error: syntax error before ')' token
configure:21719: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "linux-task-controller"
| #define PACKAGE_TARNAME "linux-task-controller"
| #define PACKAGE_VERSION "1.0.0"
| #define PACKAGE_STRING "linux-task-controller 1.0.0"
| #define PACKAGE_BUGREPORT "mapreduce-dev@hadoop.apache.org"
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define __EXTENSIONS__ 1
| #define _ALL_SOURCE 1
| #define _GNU_SOURCE 1
| #define _POSIX_PTHREAD_SEMANTICS 1
| #define _TANDEM_SOURCE 1
| #define _FILE_OFFSET_BITS 64
| #define PACKAGE "linux-task-controller"
| #define VERSION "1.0.0"
| #define HAVE_DLFCN_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE__BOOL 1
| #define HAVE_STDBOOL_H 1
| /* end confdefs.h.  */
| #include <stdio.h>
| #ifdef HAVE_SYS_TYPES_H
| # include <sys/types.h>
| #endif
| #ifdef HAVE_SYS_STAT_H
| # include <sys/stat.h>
| #endif
| #ifdef STDC_HEADERS
| # include <stdlib.h>
| # include <stddef.h>
| #else
| # ifdef HAVE_STDLIB_H
| #  include <stdlib.h>
| # endif
| #endif
| #ifdef HAVE_STRING_H
| # if !defined STDC_HEADERS && defined HAVE_MEMORY_H
| #  include <memory.h>
| # endif
| # include <string.h>
| #endif
| #ifdef HAVE_STRINGS_H
| # include <strings.h>
| #endif
| #ifdef HAVE_INTTYPES_H
| # include <inttypes.h>
| #endif
| #ifdef HAVE_STDINT_H
| # include <stdint.h>
| #endif
| #ifdef HAVE_UNISTD_H
| # include <unistd.h>
| #endif
| int
| main ()
| {
| if (sizeof ((off_t)))
| 	  return 0;
|   ;
|   return 0;
| }
configure:21742: result: yes
configure:21754: checking for size_t
configure:21782: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:21789: $? = 0
configure:21816: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
conftest.c: In function `main':
conftest.c:66: error: syntax error before ')' token
configure:21823: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "linux-task-controller"
| #define PACKAGE_TARNAME "linux-task-controller"
| #define PACKAGE_VERSION "1.0.0"
| #define PACKAGE_STRING "linux-task-controller 1.0.0"
| #define PACKAGE_BUGREPORT "mapreduce-dev@hadoop.apache.org"
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define __EXTENSIONS__ 1
| #define _ALL_SOURCE 1
| #define _GNU_SOURCE 1
| #define _POSIX_PTHREAD_SEMANTICS 1
| #define _TANDEM_SOURCE 1
| #define _FILE_OFFSET_BITS 64
| #define PACKAGE "linux-task-controller"
| #define VERSION "1.0.0"
| #define HAVE_DLFCN_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE__BOOL 1
| #define HAVE_STDBOOL_H 1
| /* end confdefs.h.  */
| #include <stdio.h>
| #ifdef HAVE_SYS_TYPES_H
| # include <sys/types.h>
| #endif
| #ifdef HAVE_SYS_STAT_H
| # include <sys/stat.h>
| #endif
| #ifdef STDC_HEADERS
| # include <stdlib.h>
| # include <stddef.h>
| #else
| # ifdef HAVE_STDLIB_H
| #  include <stdlib.h>
| # endif
| #endif
| #ifdef HAVE_STRING_H
| # if !defined STDC_HEADERS && defined HAVE_MEMORY_H
| #  include <memory.h>
| # endif
| # include <string.h>
| #endif
| #ifdef HAVE_STRINGS_H
| # include <strings.h>
| #endif
| #ifdef HAVE_INTTYPES_H
| # include <inttypes.h>
| #endif
| #ifdef HAVE_STDINT_H
| # include <stdint.h>
| #endif
| #ifdef HAVE_UNISTD_H
| # include <unistd.h>
| #endif
| int
| main ()
| {
| if (sizeof ((size_t)))
| 	  return 0;
|   ;
|   return 0;
| }
configure:21846: result: yes
configure:21858: checking whether strerror_r is declared
configure:21887: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
configure:21894: $? = 0
configure:21909: result: yes
configure:21931: checking for strerror_r
configure:21987: gcc -o conftest -DHADOOP_CONF_DIR=/etc/hadoop   conftest.c  >&5
configure:21994: $? = 0
configure:22016: result: yes
configure:22028: checking whether strerror_r returns char *
configure:22062: gcc -c -DHADOOP_CONF_DIR=/etc/hadoop  conftest.c >&5
conftest.c: In function `main':
conftest.c:70: error: invalid type argument of `unary *'
conftest.c:71: warning: initialization makes pointer from integer without a cast
configure:22069: $? = 1
configure: failed program was:
| /* confdefs.h.  */
| #define PACKAGE_NAME "linux-task-controller"
| #define PACKAGE_TARNAME "linux-task-controller"
| #define PACKAGE_VERSION "1.0.0"
| #define PACKAGE_STRING "linux-task-controller 1.0.0"
| #define PACKAGE_BUGREPORT "mapreduce-dev@hadoop.apache.org"
| #define STDC_HEADERS 1
| #define HAVE_SYS_TYPES_H 1
| #define HAVE_SYS_STAT_H 1
| #define HAVE_STDLIB_H 1
| #define HAVE_STRING_H 1
| #define HAVE_MEMORY_H 1
| #define HAVE_STRINGS_H 1
| #define HAVE_INTTYPES_H 1
| #define HAVE_STDINT_H 1
| #define HAVE_UNISTD_H 1
| #define __EXTENSIONS__ 1
| #define _ALL_SOURCE 1
| #define _GNU_SOURCE 1
| #define _POSIX_PTHREAD_SEMANTICS 1
| #define _TANDEM_SOURCE 1
| #define _FILE_OFFSET_BITS 64
| #define PACKAGE "linux-task-controller"
| #define VERSION "1.0.0"
| #define HAVE_DLFCN_H 1
| #define HAVE_UNISTD_H 1
| #define HAVE__BOOL 1
| #define HAVE_STDBOOL_H 1
| #define HAVE_DECL_STRERROR_R 1
| #define HAVE_STRERROR_R 1
| /* end confdefs.h.  */
| #include <stdio.h>
| #ifdef HAVE_SYS_TYPES_H
| # include <sys/types.h>
| #endif
| #ifdef HAVE_SYS_STAT_H
| # include <sys/stat.h>
| #endif
| #ifdef STDC_HEADERS
| # include <stdlib.h>
| # include <stddef.h>
| #else
| # ifdef HAVE_STDLIB_H
| #  include <stdlib.h>
| # endif
| #endif
| #ifdef HAVE_STRING_H
| # if !defined STDC_HEADERS && defined HAVE_MEMORY_H
| #  include <memory.h>
| # endif
| # include <string.h>
| #endif
| #ifdef HAVE_STRINGS_H
| # include <strings.h>
| #endif
| #ifdef HAVE_INTTYPES_H
| # include <inttypes.h>
| #endif
| #ifdef HAVE_STDINT_H
| # include <stdint.h>
| #endif
| #ifdef HAVE_UNISTD_H
| # include <unistd.h>
| #endif
| int
| main ()
| {
| 
| 	  char buf[100];
| 	  char x = *strerror_r (0, buf, sizeof buf);
| 	  char *p = strerror_r (0, buf, sizeof buf);
| 	  return !p || x;
| 
|   ;
|   return 0;
| }
configure:22148: result: no
configure:22165: checking for mkdir
configure:22221: gcc -o conftest -DHADOOP_CONF_DIR=/etc/hadoop   conftest.c  >&5
configure:22228: $? = 0
configure:22250: result: yes
configure:22165: checking for uname
configure:22221: gcc -o conftest -DHADOOP_CONF_DIR=/etc/hadoop   conftest.c  >&5
configure:22228: $? = 0
configure:22250: result: yes
configure:22435: creating ./config.status

## ---------------------- ##
## Running config.status. ##
## ---------------------- ##

This file was extended by linux-task-controller config.status 1.0.0, which was
generated by GNU Autoconf 2.63.  Invocation command line was

  CONFIG_FILES    = 
  CONFIG_HEADERS  = 
  CONFIG_LINKS    = 
  CONFIG_COMMANDS = 
  $ ./config.status 

on dn-177

config.status:716: creating Makefile
config.status:920: executing depfiles commands

## ---------------- ##
## Cache variables. ##
## ---------------- ##

ac_cv_build=i386-pc-solaris2.11
ac_cv_c_compiler_gnu=yes
ac_cv_c_const=yes
ac_cv_cxx_compiler_gnu=yes
ac_cv_env_CCC_set=''
ac_cv_env_CCC_value=''
ac_cv_env_CC_set=''
ac_cv_env_CC_value=''
ac_cv_env_CFLAGS_set=set
ac_cv_env_CFLAGS_value=-DHADOOP_CONF_DIR=/etc/hadoop
ac_cv_env_CPPFLAGS_set=''
ac_cv_env_CPPFLAGS_value=''
ac_cv_env_CPP_set=''
ac_cv_env_CPP_value=''
ac_cv_env_CXXCPP_set=''
ac_cv_env_CXXCPP_value=''
ac_cv_env_CXXFLAGS_set=''
ac_cv_env_CXXFLAGS_value=''
ac_cv_env_CXX_set=''
ac_cv_env_CXX_value=''
ac_cv_env_F77_set=''
ac_cv_env_F77_value=''
ac_cv_env_FFLAGS_set=''
ac_cv_env_FFLAGS_value=''
ac_cv_env_LDFLAGS_set=''
ac_cv_env_LDFLAGS_value=''
ac_cv_env_LIBS_set=''
ac_cv_env_LIBS_value=''
ac_cv_env_build_alias_set=''
ac_cv_env_build_alias_value=''
ac_cv_env_host_alias_set=''
ac_cv_env_host_alias_value=''
ac_cv_env_target_alias_set=''
ac_cv_env_target_alias_value=''
ac_cv_f77_compiler_gnu=yes
ac_cv_func_mkdir=yes
ac_cv_func_strerror_r=yes
ac_cv_func_strerror_r_char_p=no
ac_cv_func_uname=yes
ac_cv_have_decl_strerror_r=yes
ac_cv_header_dlfcn_h=yes
ac_cv_header_inttypes_h=yes
ac_cv_header_memory_h=yes
ac_cv_header_minix_config_h=no
ac_cv_header_stdbool_h=yes
ac_cv_header_stdc=yes
ac_cv_header_stdint_h=yes
ac_cv_header_stdlib_h=yes
ac_cv_header_string_h=yes
ac_cv_header_strings_h=yes
ac_cv_header_sys_stat_h=yes
ac_cv_header_sys_types_h=yes
ac_cv_header_unistd_h=yes
ac_cv_host=i386-pc-solaris2.11
ac_cv_objext=o
ac_cv_path_EGREP='/usr/gnu/bin/grep -E'
ac_cv_path_GREP=/usr/gnu/bin/grep
ac_cv_path_install='/usr/gnu/bin/install -c'
ac_cv_path_mkdir=/usr/gnu/bin/mkdir
ac_cv_prog_AWK=gawk
ac_cv_prog_CPP='gcc -E'
ac_cv_prog_CXXCPP='g++ -E'
ac_cv_prog_ac_ct_AR=ar
ac_cv_prog_ac_ct_CC=gcc
ac_cv_prog_ac_ct_CXX=g++
ac_cv_prog_ac_ct_F77=g77
ac_cv_prog_ac_ct_RANLIB=ranlib
ac_cv_prog_ac_ct_STRIP=strip
ac_cv_prog_cc_c89=''
ac_cv_prog_cc_g=yes
ac_cv_prog_cc_gcc_c_o=yes
ac_cv_prog_cxx_g=yes
ac_cv_prog_f77_g=yes
ac_cv_prog_make_make_set=yes
ac_cv_safe_to_define___extensions__=yes
ac_cv_sys_file_offset_bits=64
ac_cv_sys_largefile_CC=no
ac_cv_type__Bool=yes
ac_cv_type_off_t=yes
ac_cv_type_size_t=yes
am_cv_CC_dependencies_compiler_type=gcc3
am_cv_CXX_dependencies_compiler_type=gcc3
lt_cv_deplibs_check_method=pass_all
lt_cv_file_magic_cmd='$MAGIC_CMD'
lt_cv_file_magic_test_file=''
lt_cv_ld_reload_flag=-r
lt_cv_objdir=.libs
lt_cv_path_LD=/usr/bin/ld
lt_cv_path_LDCXX=/usr/bin/ld
lt_cv_path_NM='/usr/gnu/bin/nm -B'
lt_cv_path_SED=/usr/gnu/bin/sed
lt_cv_prog_compiler_c_o=yes
lt_cv_prog_compiler_c_o_CXX=yes
lt_cv_prog_compiler_c_o_F77=yes
lt_cv_prog_compiler_rtti_exceptions=no
lt_cv_prog_gnu_ld=no
lt_cv_prog_gnu_ldcxx=no
lt_cv_sys_global_symbol_pipe=$'sed -n -e \'s/^.*[ \t]\\([ABCDGIRSTW][ABCDGIRSTW]*\\)[ \t][ \t]*\\([_A-Za-z][_A-Za-z0-9]*\\)$/\\1 \\2 \\2/p\''
lt_cv_sys_global_symbol_to_c_name_address=$'sed -n -e \'s/^: \\([^ ]*\\) $/  {\\"\\1\\", (lt_ptr) 0},/p\' -e \'s/^[BCDEGRST] \\([^ ]*\\) \\([^ ]*\\)$/  {"\\2", (lt_ptr) \\&\\2},/p\''
lt_cv_sys_global_symbol_to_cdecl=$'sed -n -e \'s/^. .* \\(.*\\)$/extern int \\1;/p\''
lt_cv_sys_max_cmd_len=262144
lt_lt_cv_prog_compiler_c_o='"yes"'
lt_lt_cv_prog_compiler_c_o_CXX='"yes"'
lt_lt_cv_prog_compiler_c_o_F77='"yes"'
lt_lt_cv_sys_global_symbol_pipe=$'"sed -n -e \'s/^.*[ \t]\\\\([ABCDGIRSTW][ABCDGIRSTW]*\\\\)[ \t][ \t]*\\\\([_A-Za-z][_A-Za-z0-9]*\\\\)\\$/\\\\1 \\\\2 \\\\2/p\'"'
lt_lt_cv_sys_global_symbol_to_c_name_address=$'"sed -n -e \'s/^: \\\\([^ ]*\\\\) \\$/  {\\\\\\"\\\\1\\\\\\", (lt_ptr) 0},/p\' -e \'s/^[BCDEGRST] \\\\([^ ]*\\\\) \\\\([^ ]*\\\\)\\$/  {\\"\\\\2\\", (lt_ptr) \\\\&\\\\2},/p\'"'
lt_lt_cv_sys_global_symbol_to_cdecl=$'"sed -n -e \'s/^. .* \\\\(.*\\\\)\\$/extern int \\\\1;/p\'"'

## ----------------- ##
## Output variables. ##
## ----------------- ##

ACLOCAL='${SHELL} /root/mydev/hadoop-1.0.3.16/src/c++/task-controller/missing --run aclocal-1.10'
AMDEPBACKSLASH='\'
AMDEP_FALSE='#'
AMDEP_TRUE=''
AMTAR='${SHELL} /root/mydev/hadoop-1.0.3.16/src/c++/task-controller/missing --run tar'
AR='ar'
AUTOCONF='${SHELL} /root/mydev/hadoop-1.0.3.16/src/c++/task-controller/missing --run autoconf'
AUTOHEADER='${SHELL} /root/mydev/hadoop-1.0.3.16/src/c++/task-controller/missing --run autoheader'
AUTOMAKE='${SHELL} /root/mydev/hadoop-1.0.3.16/src/c++/task-controller/missing --run automake-1.10'
AWK='gawk'
CC='gcc'
CCDEPMODE='depmode=gcc3'
CFLAGS='-DHADOOP_CONF_DIR=/etc/hadoop'
CPP='gcc -E'
CPPFLAGS=''
CXX='g++'
CXXCPP='g++ -E'
CXXDEPMODE='depmode=gcc3'
CXXFLAGS='-g -O2'
CYGPATH_W='echo'
DEFS='-DPACKAGE_NAME=\"linux-task-controller\" -DPACKAGE_TARNAME=\"linux-task-controller\" -DPACKAGE_VERSION=\"1.0.0\" -DPACKAGE_STRING=\"linux-task-controller\ 1.0.0\" -DPACKAGE_BUGREPORT=\"mapreduce-dev@hadoop.apache.org\" -DSTDC_HEADERS=1 -DHAVE_SYS_TYPES_H=1 -DHAVE_SYS_STAT_H=1 -DHAVE_STDLIB_H=1 -DHAVE_STRING_H=1 -DHAVE_MEMORY_H=1 -DHAVE_STRINGS_H=1 -DHAVE_INTTYPES_H=1 -DHAVE_STDINT_H=1 -DHAVE_UNISTD_H=1 -D__EXTENSIONS__=1 -D_ALL_SOURCE=1 -D_GNU_SOURCE=1 -D_POSIX_PTHREAD_SEMANTICS=1 -D_TANDEM_SOURCE=1 -D_FILE_OFFSET_BITS=64 -DPACKAGE=\"linux-task-controller\" -DVERSION=\"1.0.0\" -DHAVE_DLFCN_H=1 -DHAVE_UNISTD_H=1 -DHAVE__BOOL=1 -DHAVE_STDBOOL_H=1 -DHAVE_DECL_STRERROR_R=1 -DHAVE_STRERROR_R=1 -DHAVE_MKDIR=1 -DHAVE_UNAME=1'
DEPDIR='.deps'
ECHO='/usr/gnu/bin/echo'
ECHO_C='\c'
ECHO_N=''
ECHO_T=''
EGREP='/usr/gnu/bin/grep -E'
EXEEXT=''
F77='g77'
FFLAGS='-g -O2'
GREP='/usr/gnu/bin/grep'
INSTALL_DATA='${INSTALL} -m 644'
INSTALL_PROGRAM='${INSTALL}'
INSTALL_SCRIPT='${INSTALL}'
INSTALL_STRIP_PROGRAM='$(install_sh) -c -s'
LDFLAGS=''
LIBOBJS=''
LIBS=''
LIBTOOL='$(SHELL) $(top_builddir)/libtool'
LN_S='ln -s'
LTLIBOBJS=''
MAKEINFO='${SHELL} /root/mydev/hadoop-1.0.3.16/src/c++/task-controller/missing --run makeinfo'
MKDIR_P='/usr/gnu/bin/mkdir -p'
OBJEXT='o'
PACKAGE='linux-task-controller'
PACKAGE_BUGREPORT='mapreduce-dev@hadoop.apache.org'
PACKAGE_NAME='linux-task-controller'
PACKAGE_STRING='linux-task-controller 1.0.0'
PACKAGE_TARNAME='linux-task-controller'
PACKAGE_VERSION='1.0.0'
PATH_SEPARATOR=':'
RANLIB='ranlib'
SET_MAKE=''
SHELL='/bin/sh'
STRIP='strip'
VERSION='1.0.0'
ac_ct_CC='gcc'
ac_ct_CXX='g++'
ac_ct_F77='g77'
am__fastdepCC_FALSE='#'
am__fastdepCC_TRUE=''
am__fastdepCXX_FALSE='#'
am__fastdepCXX_TRUE=''
am__include='include'
am__isrc=' -I$(srcdir)'
am__leading_dot='.'
am__quote=''
am__tar='${AMTAR} chof - "$$tardir"'
am__untar='${AMTAR} xf -'
bindir='${exec_prefix}/bin'
build='i386-pc-solaris2.11'
build_alias=''
build_cpu='i386'
build_os='solaris2.11'
build_vendor='pc'
datadir='${datarootdir}'
datarootdir='${prefix}/share'
docdir='${datarootdir}/doc/${PACKAGE_TARNAME}'
dvidir='${docdir}'
exec_prefix='${prefix}'
host='i386-pc-solaris2.11'
host_alias=''
host_cpu='i386'
host_os='solaris2.11'
host_vendor='pc'
htmldir='${docdir}'
includedir='${prefix}/include'
infodir='${datarootdir}/info'
install_sh='$(SHELL) /root/mydev/hadoop-1.0.3.16/src/c++/task-controller/install-sh'
libdir='${exec_prefix}/lib'
libexecdir='${exec_prefix}/libexec'
localedir='${datarootdir}/locale'
localstatedir='${prefix}/var'
mandir='${datarootdir}/man'
mkdir_p='/usr/gnu/bin/mkdir -p'
oldincludedir='/usr/include'
pdfdir='${docdir}'
prefix='/root/mydev/hadoop-1.0.3.16/build/hadoop-1.0.4-SNAPSHOT'
program_transform_name='s,x,x,'
psdir='${docdir}'
sbindir='${exec_prefix}/sbin'
sharedstatedir='${prefix}/com'
sysconfdir='${prefix}/etc'
target_alias=''

## ----------- ##
## confdefs.h. ##
## ----------- ##

#define PACKAGE_NAME "linux-task-controller"
#define PACKAGE_TARNAME "linux-task-controller"
#define PACKAGE_VERSION "1.0.0"
#define PACKAGE_STRING "linux-task-controller 1.0.0"
#define PACKAGE_BUGREPORT "mapreduce-dev@hadoop.apache.org"
#define STDC_HEADERS 1
#define HAVE_SYS_TYPES_H 1
#define HAVE_SYS_STAT_H 1
#define HAVE_STDLIB_H 1
#define HAVE_STRING_H 1
#define HAVE_MEMORY_H 1
#define HAVE_STRINGS_H 1
#define HAVE_INTTYPES_H 1
#define HAVE_STDINT_H 1
#define HAVE_UNISTD_H 1
#define __EXTENSIONS__ 1
#define _ALL_SOURCE 1
#define _GNU_SOURCE 1
#define _POSIX_PTHREAD_SEMANTICS 1
#define _TANDEM_SOURCE 1
#define _FILE_OFFSET_BITS 64
#define PACKAGE "linux-task-controller"
#define VERSION "1.0.0"
#define HAVE_DLFCN_H 1
#define HAVE_UNISTD_H 1
#define HAVE__BOOL 1
#define HAVE_STDBOOL_H 1
#define HAVE_DECL_STRERROR_R 1
#define HAVE_STRERROR_R 1
#define HAVE_MKDIR 1
#define HAVE_UNAME 1

configure: exit 0
